---
layout:     post
title:      "浅谈Top K问题"
subtitle:   "Top K"
date:       2021-01-26 20:21:00
author:     "Kris"
catalog: false
header-style: text
tags:
  - System Design
  - Algorithms
---

## 1. 背景

这篇文章浅谈**Top K问题**(也有一个类似的问题叫**The Heavy Hitters Problem**，主要是寻找出现频数较高的数值)。Top K问题在我们的日常生活中也是处处可见，如购物平台的推荐商品，搜索热词，检测较大流量的TCP连接(检测DDoS)等等。本文主要通过**Top K**问题来阐述**MapReduce**在大数据处理中的应用，详细描述了在单台机器上，多台机器上，低的QPS，高的QPS中MapReduce如何工作，最后简单介绍了近似算法来解决Top K问题。

## 2. 阐述Top K问题

我们先来看看一个简化了的Top K问题：输入是一个长度为**n**的数组**A**以及一个参数**k**，**n**是一个非常大的数，如几百万，几千万，而**k**是一个相对较小的数，如10，100或1000。目标就是找到在数组**A**里出现频数至少是**n/k**的数值。

在阐述如何解决Top K问题之前，先让我们来看一个读书时老师会问到的问题(题目来源于LeetCode)：

[(Top K Frequent Elements) Given a non-empty array of integers, return the k most frequent elements.](https://leetcode-cn.com/problems/top-k-frequent-elements/)

接下来我会以这个问题为例进行Top K问题的介绍。

### 2.1 Top K on Single Node

在**单结点**(一台机器)上解决Top K问题（或者在单台机器上解决问题），通常用到的数据结构是**HashMap**和**Heap**(小顶堆), 时间复杂度是**O(n + n * lgk) = O(n * lgk)**, 空间复杂度是**O(n + k)**, **n**是不重复数值的个数。

- **HashMap**主要是记录每个元素出现的频数
- 把HashMap中记录的数值放进小顶堆(大小为K)，当堆还没满时，直接把数值放进去就行
- 当堆满时，比较堆顶的数值和准备放进堆的数值，如果准备放进堆的数值的频数比堆顶数值频数大，把堆顶数值踢掉，放进新的数值，反之不做任何操作。
- 最后堆里就存储了Top K的数值(出现频数的Top K数值)。
- 以下以python为例简单写下此过程，而关于堆的实现，可以参考[Algorithms, 4th Edition](https://algs4.cs.princeton.edu/home/) (非常棒的介绍算法的书籍) 。

```python
from Queue import PriorityQueue

class Solution(object):
    def topKFrequent(self, nums, k):
        """
        :type nums: List[int]
        :type k: int
        :rtype: List[int]
        """
        m = {}
        for num in nums:
            m[num] = m.get(num, 0) + 1
        
        q = PriorityQueue()
        for num in m:
            q.put([m[num], num])
            if q.qsize() > k:
                q.get()
        
        ans = []
        while q.qsize() > 0:
            ans.append(q.get()[1])

        return ans
```

### 2.2 Top K on Multiple Node

但是当数据量非常大的时候，单机处理Top K是否恰当。比如有**一组100T的文件，文件内容是10亿**用户当天的搜索记录，求当天搜索的热搜词。如果继续用单机处理这个问题，主要会出现两个问题：文件太大内存不够，处理速度非常慢。这时候，我们可以考虑用多台机器进行**MapReduce**处理，关于MapReduce可以参考之前的分享[浅谈海量数据](https://drive.google.com/file/d/1fftN6yrv_4kyLeLBclI6XZtc9y8NRWx1/view?usp=sharing)。

- 可以每次从100T的文件中每次读取1G的文件，进行搜索词拆分并进行哈希处理，发送到相对应的机器进行Top K处理。
- 把各个机器的Top K搜索词进行合并，并取其中的Top K搜索词。( **list of Top K {top k1, top k2, ...} => merge to get final top k** )

![](/img/2021/2021-01-26-2.1_MapReduce_Process.png)

### 2.3 Realtime Top K with low QPS
之前讨论的Top K问题都是对于**静态数据**来说的。现在又有另外一个场景，有**实时数据**的流入，我们应该如何解决Top K问题呢？

想法一：

- 当有新数据流入时，把数据写入磁盘中
- 当有请求Top K时，基于磁盘上的数据求解Top K
- 
这样做主要有两个问题：

- 重复计算，每次都要基于磁盘中的数据重新进行Top K求解
- 计算速度太慢了

想法二：

- 当有新数据流入时，把数据存储在HashMap
- 当HashMap更新了，相对应更新Priority Queue
- 从Priority Queue得到Top K

这样做主要有两个问题：

- OOM (内存不够)
- 当机器挂掉时候会丢失当前的数据

那么为什么会导致内存不够呢？**HashMap** ? 还是**Priority Queue** ?

我觉得是HashMap会导致内存不够，因为Priority Queue只是会保存K个key-value数值对，而**HashMap则是不断地新增数值，最终导致内存不够用**。

现在，我们可以尝试用**数据库(如MySQL)去替代HashMap**，这样我们可以把单词的频数存储在数据库中，如下：

| id        | word          | count  |
| ----------|:-------------:| -----: |
| 1         | computer      | 10     |
| 2         | science       | 9      |

这时候如果还用Priority Queue去保存Top K的值就会出现问题。如果用数据库替代HashMap，新的单词可以跟以前一样，直接和小顶堆的根值比较即可；但**如果这个单词已经存在于小顶堆里面，我们需要更新该单词在小顶堆中的值，而不是让该单词直接和小顶堆的根值进行比较**。

这时候，我们可以考虑用TreeMap去代替**Priority Queue**。**TreeMap**是有序的key-value集合，通过红黑树来实现，支持查找和删除操作，可以在O(logn)时间内做查找，插入和删除等操作。这样对于已经存在于TreeMap的单词，我们可以更新该单词对应的频数值。

### 2.4 Realtime Top K with high QPS
但是当数据流有**很高的QPS**，这时候我们应该如何去解决这个问题呢？QPS很高，意味着数据库不能实时地做出反应，因为读写的频率太高了，这导致了**很高的延迟性(high latency)**。

这时候我们可以考虑2.2提到的多节点处理Top K的方法去解决这个问题。但是当某个单词非常热门，这会导致某个节点的 写QPS 会非常高，同样又会导致**2.2很高的延迟性(high latency)**2.2。流程如下：

![](/img/2021/2021-01-26-2.2_MapReduce_Process.png)

- 新的数据发送给Slave 1进行处理
- Slave 1会把新的数据存储在数据库上
- 数据库的更新会触发TreeMap的更新，此时TreeMap会先进入block状态，然后对新数据进行更新
- 此时Master接收到Top K的请求
- Master Node会去请求Slave 1，返回Top K
- Slave 1就会去TreeMap请求Top K
- 因为数据流**有非常高的QPS**，数据库不停的进行读写操作，相对应TreeMap不停地进行**Block和Update操作**，此时TreeMap还**处于Block**状态，于是返回Wait消息给Slave 1
- Slave 1返回Wait的消息给Mater Node，此时Master Node并不能实时得到Top K的数据，**导致很高的延迟性**

就像是算法里面的时间复杂度和空间复杂度，通过**增加空间复杂度来降低时间复杂度**，比如用并查集解决朋友圈问题。对于上面阐述的高延迟性问题，同样可以**牺牲一点精确性来减少**延迟性。这时候我们可以利用**缓存**来解决高延迟性的问题。流程如下：

![](/img/2021/2021-01-26-2.3_MapReduce_Process_Cache.png)

- 新的数据发送给Slave 1进行处理
- Slave 1会把新的数据缓存起来
- 每隔一段时间，如每隔10秒缓存会把缓存的数据存储在数据库上
- 数据库的更新会触发TreeMap的更新，此时TreeMap会先进入block状态，然后对新数据进行更新
- 此时Master接收到Top K的请求
- Master Node会去请求Slave 1，返回Top K
- Slave 1就会去TreeMap请求Top K
- 此时因为数据的更新并不是特别频繁，TreeMap并没有一直处于block状态，此时TreeMap返回Top K数值
- Slave 1返回Top K数值给Mater Node

### 2.5 Approximate Top K

现在有一个问题，对于高频词问题，肯定会有很多单词出现的频率非常低，这样**低频词会占据磁盘很大部分的容量**。就像2.4提到的用缓存解决高QPS的Top K问题，适当**降低精确性来提高空间的使用率**。接下来我们来看看**Count-Min Sketch**和**Lossy Counting**如何解决**Top K**问题，这两个近似算法都是优化了存储单词出现频数的方法 [1][2]，计算Top K那部分依旧是用小顶堆或Tree Map来解决。

### 2.5.1 Count-Min Sketch

**Count-Min Sketch**类似于**Bloom Filter**，都是用多个哈希函数去解决冲突问题 [1][2][3]。假设我们有**d个哈希函数**，一个数组T(d行，m列)，对于数据流中的每个数据，用d个哈希函数计算得到**d个哈希值**，把其d个哈希值对**m进行取模运算**，并对其所在数组的位置的值**加一**，即T[hash_func][hash_value] + 1。当我们去搜索某个单词的频数时，通过d个哈希函数我们可以得到**d个哈希值**，相对应可以找到d个哈希值对应其所在的数组的值，这时我们**选择数值最小的数值**作为该单词的**频数** [4]。

![](./img/2021/2.4_CountMinSketch.png)

**Count-Min Sketch**的优点就是可以**节省很多空间**；缺点是对于低频词，有可能通过计算把该单词变成高频词。

### 2.5.2 Losssy Counting

**Lossy Counting**是另一个用来解决数据流中的Top K问题的近似算法，对于数据流中的数据，如果**其出现频数超过某个自定义的数值**，就把该数值记录下来 [3]。首先我们先创建一个HashMap，用来存储单词的频数(key是单词，value是其频数)，然后建立**data frame(如数组)**，如下：

![](/img/2021/2021-01-26-2.5_DataFrame.png)

从数据流中读取数值，并把数据放进**data frame**中，统计其**频数f**，并将**其频数减一**(我觉得这是非常非常非常聪明的一种做法)，如下：

![](/img/2021/2021-01-26-2.6_DataFrame.png)

把计算得到的频数放进**HashMap**中，并把HashMap中**频数为0**的key-value数值对**删除**(这就是为什么计算频数时需要将其减一的原因)。重复以上步骤，以此来统计单词出现的频数，如下：

![](/img/2021/2021-01-26-2.7_DataFrame.png)

这个方法背后的思想主要是即使在**每个data frame**中计算频数时都要减一，但是高频词出现的频率就很高，这就说明**在每一个data frame中高频词在HashMap中被删除的几率会很低**。当我们不断从数据流中读取数据，**低频词在HashMap中记录的频数会越来越低，直至到零时就会从HashMap中删除掉[3][5]**。

## 3. 总结

**Top K**问题在我们的日常生活中是处处可见，如购物平台的推荐商品，搜索热词，检测较大流量的TCP连接(检测DDoS)等等。在单台机器上，解决**Top K**问题，通常需要堆的帮助选择出现频数最高的K个数值。但是当数据越来越大的时候，单台机器通常内存不足以处理如此庞大的数据，这时候就需要用到多台机器对数据进行**Map和Reduce合并处理**。但是实际生活中，数据是流动的，不断增加的，当机器的**QPS比较低**的时候，这时候可以用**数据库存**储记录每个数值出现的频数，每当有新的数据时，更新数据库，并把此数值的频数和小顶堆的根值比较即可，这时候，我们可以考虑用**TreeMap**去代替Priority Queue，因为**TreeMap是有序的key-value集合**，通过红黑树来实现，支持查找和删除操作，可以在O(logn)时间内做查找，插入和删除等操作。当机器的QPS比较高的时候，因为读写频率比较高，此时如果不停的访问数据库，很容易造成很高的延迟性，这时候可以**缓存**一部分数据来解决高延迟性的问题。此外，如果可以接受结果会有一些偏差，我们也可以使用一些**近似算法来解决数据流的Top K问题**，如Count-Min Sketch和Losssy Counting。

## References

**[1]** T. Roughgarden, G. Valiant (Mar. 30, 2016). Stanford University CS168: The Modern Algorithmic Toolbox Lecture #2: Approximate Heavy Hitters and the Count-Min Sketch. Retrieved from http://theory.stanford.edu/~tim/s17/l/l2.pdf.

**[2]** Vazirani, Rao. University of California, Berkeley, CS270: Lecture 15 Streaming Algorithms: Frequent Items. Retrieved from https://people.eecs.berkeley.edu/~satishr/cs270/sp11/rough-notes/Streaming-two.pdf.

**[3]** M. Vogiatzis (July 18, 2015). Frequency Counting Algorithms over Data Streams. Retrieved from https://micvog.com/2015/07/18/frequency-counting-algorithms-over-data-streams/.

**[4]** Z. Jiang (Nov. 13, 2017), Top K Frequent Items Algorithms. Retrieved from https://zpjiang.me/2017/11/13/top-k-elementes-system-design/.

**[5]** M. Hadjieleftheriou, S. Muthukrishnan, R. Berinde, P. Indyk, M. Strauss. Finding Frequent Items in Data Streams. Retrieved from http://archive.dimacs.rutgers.edu/Workshops/WGUnifyingTheory/Slides/cormode.pdf.